{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lecture 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec, mat = tf.constant([2,2], name=\"vector\"), tf.constant([[0,1],[3,4]], name=\"matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'zeros:0' shape=(2, 2) dtype=int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros(vec, tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [0 0]]\n",
      "Tensor(\"vector:0\", shape=(2,), dtype=int32) [2 2]\n",
      "Tensor(\"matrix:0\", shape=(2, 2), dtype=int32) [[0 1]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "    print(tf.zeros(vec, tf.int32).eval())\n",
    "    print(vec, vec.eval())\n",
    "    print(mat, mat.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"zeros_like:0\", shape=(2,), dtype=int32) [0 0]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "    print(tf.zeros_like(vec), tf.zeros_like(vec).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.client.session.InteractiveSession at 0xa8dfa94320>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'ones_1:0' shape=(5, 2) dtype=float32>, array([[1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.],\n",
       "        [1., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones([5,2]), tf.ones([5,2]).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[7, 7, 7, 7, 7],\n",
       "        [7, 7, 7, 7, 7]]), <tf.Tensor 'Fill_1:0' shape=(2, 5) dtype=int32>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fill([2,5],7).eval(), tf.fill([2,5],7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'start' has DataType int32 not in list of allowed values: bfloat16, float32, float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-f3c26cd2d3a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mlin_space\u001b[1;34m(start, stop, num, name)\u001b[0m\n\u001b[0;32m   4470\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4471\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 4472\u001b[1;33m         \"LinSpace\", start=start, stop=stop, num=num, name=name)\n\u001b[0m\u001b[0;32m   4473\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4474\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'start' has DataType int32 not in list of allowed values: bfloat16, float32, float64"
     ]
    }
   ],
   "source": [
    "tf.lin_space(1,9,0.8).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'num' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5a6c70db9a1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlin_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mlin_space\u001b[1;34m(start, stop, num, name)\u001b[0m\n\u001b[0;32m   4470\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4471\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 4472\u001b[1;33m         \"LinSpace\", start=start, stop=stop, num=num, name=name)\n\u001b[0m\u001b[0;32m   4473\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4474\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[0;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 609\u001b[1;33m                                        param_name=input_name)\n\u001b[0m\u001b[0;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[1;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[0;32m     58\u001b[0m           \u001b[1;34m\"allowed values: %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[1;32m---> 60\u001b[1;33m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Value passed to parameter 'num' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "tf.lin_space(1.0,9.0,0.8).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        2.142857  3.2857144 4.4285717 5.571429  6.714286  7.8571434\n",
      " 9.       ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.lin_space(1.0,9.0,8).eval())\n",
    "len(tf.lin_space(1.0,9.0,8).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  4.  6.  8. 10.]\n",
      "[ 0.  2.  4.  6.  8. 10.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  2.,  4.,  6.,  8., 10.], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tf.range(0., 11, 2).eval())\n",
    "print(tf.range(0., 12., 2).eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  2.  4.  6.  8. 10.] 12.000000001\n",
      "[ 0.  2.  4.  6.  8. 10.] 12.00000001\n",
      "[ 0.  2.  4.  6.  8. 10.] 12.0000001\n",
      "[ 0.  2.  4.  6.  8. 10. 12.] 12.000001\n",
      "[ 0.  2.  4.  6.  8. 10. 12.] 12.00001\n",
      "[ 0.  2.  4.  6.  8. 10. 12.] 12.0001\n"
     ]
    }
   ],
   "source": [
    "for m in range(9,3,-1):\n",
    "    print(tf.range(0., 12 + 10**(-m), 2).eval(), 12+10**(-m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [3 4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3, 4],\n",
       "       [0, 1]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mat.eval())\n",
    "tf.random_shuffle(mat).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.8095361   0.7171352 ]\n",
      "  [-0.3160582   0.57229537]]\n",
      "\n",
      " [[ 2.4878109  -1.2849234 ]\n",
      "  [-0.17564026 -0.17201276]]\n",
      "\n",
      " [[ 2.4339795  -0.20659003]\n",
      "  [ 1.1018362  -1.1203471 ]]]\n"
     ]
    }
   ],
   "source": [
    "mat = tf.random_normal([3,2,2])\n",
    "mat = tf.constant(mat.eval())\n",
    "print(mat.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.8095361   0.7171352 ]\n",
      "  [-0.3160582   0.57229537]]\n",
      "\n",
      " [[ 2.4878109  -1.2849234 ]\n",
      "  [-0.17564026 -0.17201276]]\n",
      "\n",
      " [[ 2.4339795  -0.20659003]\n",
      "  [ 1.1018362  -1.1203471 ]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6, [array([[[ 2.4339795 , -0.20659003],\n",
       "          [ 1.1018362 , -1.1203471 ]],\n",
       "  \n",
       "         [[ 2.4878109 , -1.2849234 ],\n",
       "          [-0.17564026, -0.17201276]],\n",
       "  \n",
       "         [[ 0.8095361 ,  0.7171352 ],\n",
       "          [-0.3160582 ,  0.57229537]]], dtype=float32),\n",
       "  array([[[ 2.4339795 , -0.20659003],\n",
       "          [ 1.1018362 , -1.1203471 ]],\n",
       "  \n",
       "         [[ 0.8095361 ,  0.7171352 ],\n",
       "          [-0.3160582 ,  0.57229537]],\n",
       "  \n",
       "         [[ 2.4878109 , -1.2849234 ],\n",
       "          [-0.17564026, -0.17201276]]], dtype=float32),\n",
       "  array([[[ 0.8095361 ,  0.7171352 ],\n",
       "          [-0.3160582 ,  0.57229537]],\n",
       "  \n",
       "         [[ 2.4878109 , -1.2849234 ],\n",
       "          [-0.17564026, -0.17201276]],\n",
       "  \n",
       "         [[ 2.4339795 , -0.20659003],\n",
       "          [ 1.1018362 , -1.1203471 ]]], dtype=float32),\n",
       "  array([[[ 2.4878109 , -1.2849234 ],\n",
       "          [-0.17564026, -0.17201276]],\n",
       "  \n",
       "         [[ 0.8095361 ,  0.7171352 ],\n",
       "          [-0.3160582 ,  0.57229537]],\n",
       "  \n",
       "         [[ 2.4339795 , -0.20659003],\n",
       "          [ 1.1018362 , -1.1203471 ]]], dtype=float32),\n",
       "  array([[[ 0.8095361 ,  0.7171352 ],\n",
       "          [-0.3160582 ,  0.57229537]],\n",
       "  \n",
       "         [[ 2.4339795 , -0.20659003],\n",
       "          [ 1.1018362 , -1.1203471 ]],\n",
       "  \n",
       "         [[ 2.4878109 , -1.2849234 ],\n",
       "          [-0.17564026, -0.17201276]]], dtype=float32),\n",
       "  array([[[ 2.4878109 , -1.2849234 ],\n",
       "          [-0.17564026, -0.17201276]],\n",
       "  \n",
       "         [[ 2.4339795 , -0.20659003],\n",
       "          [ 1.1018362 , -1.1203471 ]],\n",
       "  \n",
       "         [[ 0.8095361 ,  0.7171352 ],\n",
       "          [-0.3160582 ,  0.57229537]]], dtype=float32)])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tf.random_shuffle은 첫 번째 디멘션으로만 섞는다.\n",
    "import numpy as np\n",
    "#mat = tf.constant([[[5,2],[2,1]],[[1,1],[3,2]]])\n",
    "print(mat.eval())\n",
    "temp = [tf.random_shuffle(mat).eval()]\n",
    "for _ in range(50):\n",
    "    sfd = tf.random_shuffle(mat).eval()\n",
    "    if not (sum(1 for e in temp if np.all(sfd==e))):\n",
    "        temp.append(sfd)\n",
    "len(temp), temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9893097, 3.4579384)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# truncated는 2 std 밖의 값은 뽑지 않는다.\n",
    "max_truncated, max_normal = -9, -9\n",
    "for _ in range(100):\n",
    "    max_truncated = max(np.max(tf.truncated_normal([1,10]).eval()), max_truncated)\n",
    "    max_normal = max(np.max(tf.random_normal([1,10]).eval()), max_normal)\n",
    "max_truncated, max_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.8095361   0.7171352 ]\n",
      "  [-0.3160582   0.57229537]]\n",
      "\n",
      " [[ 2.4878109  -1.2849234 ]\n",
      "  [-0.17564026 -0.17201276]]\n",
      "\n",
      " [[ 2.4339795  -0.20659003]\n",
      "  [ 1.1018362  -1.1203471 ]]] [3, 2, 2]\n",
      "[[[-0.17564026 -0.17201276]]\n",
      "\n",
      " [[ 1.1018362  -1.1203471 ]]] 2,1,2\n",
      "[[[0.8095361]]\n",
      "\n",
      " [[2.4878109]]\n",
      "\n",
      " [[2.4339795]]] 3,1,1\n",
      "[[[ 0.8095361 ]\n",
      "  [-0.3160582 ]]\n",
      "\n",
      " [[ 2.4878109 ]\n",
      "  [-0.17564026]]] 2,2,1\n"
     ]
    }
   ],
   "source": [
    "print(mat.eval(),[3,2,2])\n",
    "print(tf.random_crop(mat,tf.constant([2,1,2])).eval(),'2,1,2')\n",
    "print(tf.random_crop(mat,tf.constant([3,1,1])).eval(),'3,1,1')\n",
    "print(tf.random_crop(mat,tf.constant([2,2,1])).eval(),'2,2,1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as s:\n",
    "    print(s.run(tf.report_uninitialized_variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "100\n",
      "1001\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(10)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(W.initializer)\n",
    "    print(W.eval())\n",
    "    W.assign(100).eval()\n",
    "    print(W.eval())\n",
    "    sess.run(W.assign(1001))\n",
    "    print(W.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = tf.Variable(123)\n",
    "W.assign(100).eval()\n",
    "W.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable.initialized_value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lecture 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss Tensor(\"loss:0\", dtype=float32) -6.0702143 84.92951\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "DATA_FILE = \"data/birth_life_2010.txt\"\n",
    "\n",
    "\n",
    "# Step 1: read in data from the .txt file\n",
    "\n",
    "# data is a numpy array of shape (190, 2), each row is a datapoint\n",
    "\n",
    "data, n_samples = utils.read_birth_life_data(DATA_FILE)\n",
    "\n",
    "\n",
    "# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\n",
    "\n",
    "X = tf.placeholder(tf.float32, name='X')\n",
    "\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "\n",
    "# Step 3: create weight and bias, initialized to 0\n",
    "\n",
    "w = tf.get_variable('weights', initializer=tf.constant(0.0))\n",
    "\n",
    "b = tf.get_variable('bias', initializer=tf.constant(0.0))\n",
    "\n",
    "\n",
    "# Step 4: construct model to predict Y (life expectancy from birth rate)\n",
    "Y_predicted = w * X + b \n",
    "\n",
    "\n",
    "# Step 5: use the square error as the loss function\n",
    "\n",
    "loss = tf.square(Y - Y_predicted, name='loss')\n",
    "\n",
    "\n",
    "# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    " \n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "\n",
    "    \n",
    "\n",
    "    # Step 8: train the model\n",
    "\n",
    "    for i in range(100): # run 100 epochs\n",
    "\n",
    "        for x, y in data:\n",
    "\n",
    "            # Session runs train_op to minimize loss\n",
    "\n",
    "            sess.run(optimizer, feed_dict={X: x, Y:y}) \n",
    "\n",
    "    \n",
    "\n",
    "    # Step 9: output the values of w and b\n",
    "    w_out, b_out = sess.run([w, b]) \n",
    "    print('loss', loss, w_out, b_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_loss(labels,predictions, delta=14.0):\n",
    "    residual = tf.abs(labels - predictions)\n",
    "    def f1(): return 0.5 * tf.square(residual)\n",
    "    def f2(): return delta * residual - 0.5 * tf.square(delta)\n",
    "    return tf.cond(residual < delta, f1, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss Tensor(\"cond/Merge:0\", dtype=float32) -4.2249994 78.485054\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import utils\n",
    "\n",
    "\n",
    "DATA_FILE = \"data/birth_life_2010.txt\"\n",
    "\n",
    "\n",
    "# Step 1: read in data from the .txt file\n",
    "\n",
    "# data is a numpy array of shape (190, 2), each row is a datapoint\n",
    "\n",
    "data, n_samples = utils.read_birth_life_data(DATA_FILE)\n",
    "\n",
    "\n",
    "# Step 2: create placeholders for X (birth rate) and Y (life expectancy)\n",
    "\n",
    "X = tf.placeholder(tf.float32, name='X')\n",
    "\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "\n",
    "# Step 3: create weight and bias, initialized to 0\n",
    "\n",
    "w = tf.get_variable('weights', initializer=tf.constant(0.0))\n",
    "\n",
    "b = tf.get_variable('bias', initializer=tf.constant(0.0))\n",
    "\n",
    "\n",
    "# Step 4: construct model to predict Y (life expectancy from birth rate)\n",
    "Y_predicted = w * X + b \n",
    "\n",
    "\n",
    "# Step 5: use the square error as the loss function\n",
    "\n",
    "#loss = tf.square(Y - Y_predicted, name='loss')\n",
    "loss = huber_loss(Y, Y_predicted)\n",
    "\n",
    "\n",
    "# Step 6: using gradient descent with learning rate of 0.01 to minimize loss\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss)\n",
    "\n",
    " \n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "\n",
    "    \n",
    "\n",
    "    # Step 8: train the model\n",
    "\n",
    "    for i in range(100): # run 100 epochs\n",
    "\n",
    "        for x, y in data:\n",
    "\n",
    "            # Session runs train_op to minimize loss\n",
    "\n",
    "            sess.run(optimizer, feed_dict={X: x, Y:y}) \n",
    "\n",
    "    \n",
    "\n",
    "    # Step 9: output the values of w and b\n",
    "    w_out, b_out = sess.run([w, b]) \n",
    "    print('loss', loss, w_out, b_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tf.float32, tf.float32) (TensorShape([]), TensorShape([]))\n"
     ]
    }
   ],
   "source": [
    "data, n_samples = utils.read_birth_life_data('data/birth_life_2010.txt')\n",
    "\n",
    "#dataset 이용\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data[:,0], data[:,1]))\n",
    "print(dataset.output_types, dataset.output_shapes)\n",
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.822, 74.82825]\n",
      "[3.869, 70.81949]\n",
      "[3.911, 72.15066]\n",
      "[5.578, 61.999855]\n",
      "[1.579, 73.92766]\n"
     ]
    }
   ],
   "source": [
    "iterator = dataset.make_one_shot_iterator()\n",
    "X, Y = iterator.get_next()\n",
    "with tf.Session() as sess:\n",
    "    for i in range(5):\n",
    "        print(sess.run([X, Y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient 직접 수정하기\n",
    "'''\n",
    "optimizer.compute_gradients(loss, list of variables)\n",
    "-> [(gradient, variable), ... ]  반환. 여기에 수정 가한 뒤\n",
    "optimizer.apply_gradients(적용할 변수)\n",
    "\n",
    "'''\n",
    "\n",
    "# gradient 멈추기\n",
    "'''\n",
    "tf.stop_gradient 사용.\n",
    "'''\n",
    "\n",
    "# 특정 gradient만 계산하기\n",
    "'''\n",
    "tf.gradients 사용\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_folder = 'data/mnist'\n",
    "utils.download_mnist(mnist_folder)\n",
    "train, val, test = utils.read_mnist(mnist_folder, flatten = True)\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices(train)\n",
    "test_data = tf.data.Dataset.from_tensor_slices(test)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_data = train_data.batch(batch_size)\n",
    "test_data = test_data.batch(batch_size)\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types, train_data.output_shapes)\n",
    "\n",
    "img, label = iterator.get_next()\n",
    "\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "test_init = iterator.make_initializer(test_data)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    #tf.nn.conv2d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lecture 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 1.11.0\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[4.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = [[2.]]\n",
    "m = tf.matmul(x, x)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "(3,)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c5995de2df22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_shape.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    614\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mTensorShape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 616\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    617\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    618\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "x = tf.constant([1., 2., 3.])\n",
    "assert type(x.numpy()) == np.ndarray\n",
    "squared = np.square(x)\n",
    "\n",
    "squared = tf.square(squared)\n",
    "\n",
    "for i in x:\n",
    "    print(i)\n",
    "    \n",
    "print(x.shape)\n",
    "for i in range(x.shape[0]):\n",
    "    for j in range(x.shape[1]):\n",
    "        print(x[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n",
      "[<tf.Tensor: id=61, shape=(), dtype=float32, numpy=6.0>]\n"
     ]
    }
   ],
   "source": [
    "def square(x):\n",
    "    return x ** 2\n",
    "\n",
    "import tensorflow.contrib.eager as tfe\n",
    "grad = tfe.gradients_function(square)\n",
    "\n",
    "print(square(3.))\n",
    "print(grad(3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "[(<tf.Tensor: id=119, shape=(), dtype=float32, numpy=-24.0>, <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=2.0>)]\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(2.)\n",
    "def loss(y):\n",
    "    return (y - x ** 2) ** 2\n",
    "\n",
    "grad = tfe.implicit_gradients(loss)\n",
    "\n",
    "print(loss(7.))\n",
    "print(grad(7.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-1f8dc4b455d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mw2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimplicit_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    270\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[1;34m\"\"\"Computes the gradient of the wrapped function.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mimplicit_val_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\flowme\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py\u001b[0m in \u001b[0;36mgrad_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[0mthis_tape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpush_new_tape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 204\u001b[1;33m       \u001b[0mend_node\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mend_node\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         raise ValueError(\"Cannot differentiate a function that returns None; \"\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object is not callable"
     ]
    }
   ],
   "source": [
    "i = tf.Variable([[1.],[2.]])\n",
    "w1 = tf.Variable([1.,1.])\n",
    "w2 = tf.multiply(w1,i)\n",
    "grad = tfe.implicit_gradients(w2)\n",
    "grad(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
